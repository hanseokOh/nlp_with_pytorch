{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3장 Hello 파이토치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T12:58:05.086576Z",
     "start_time": "2020-01-29T12:58:05.080562Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T13:20:06.951014Z",
     "start_time": "2020-01-29T13:20:06.946021Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.0'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3.1 텐서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T12:58:50.167185Z",
     "start_time": "2020-01-29T12:58:50.150194Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n",
      "[[1 2]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[1,2],[3,4]])\n",
    "print(x)\n",
    "x = torch.from_numpy(np.array([[1,2],[3,4]]))\n",
    "print(x)\n",
    "x = np.array([[1,2],[3,4]])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.Tensor를 통해 선언하면 디폴트 타입인 torch.FloatTensor로 선언하는 것과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3.3 Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T13:08:08.770188Z",
     "start_time": "2020-01-29T13:08:08.757226Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000e+00, 1.0597e-05],\n",
      "        [1.3526e-01, 9.1816e-41]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor(2,2)\n",
    "y = torch.FloatTensor(2,2)\n",
    "y.requires_grad_(True)\n",
    "\n",
    "z = (x+y) + torch.FloatTensor(2,2)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파이토치에서는 정해진 연산이라는 것은 없고, 모델은 배워야 하는 파라미터 텐서만 미리 알고 있을 뿐, 그 가중치 파라미터들이 어떠한 연산을 통해 학습 또는 연산에 관여하는지는 알 수 없음. 연산이 수행된 직후에 알 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기울기를 구할 필요가 없는 연산에 대해서는 with 문법을 사용하여 연산을 수행할 수 있음\n",
    "\n",
    "- 역전파 알고리즘 수행이 필요 없는 비 학습 과정 (예측, 추론) 등을 할 때 유용\n",
    "- 기울기를 구하기 위한 사전 작업을 생략할 수 있음\n",
    "\n",
    "=> 연산 속도 및 메모리 사용 측면에서도 큰 이점"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T13:08:29.133749Z",
     "start_time": "2020-01-29T13:08:29.122751Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000e+00, 1.0597e-05],\n",
      "        [2.0289e-01, 1.3772e-40]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor(2,2)\n",
    "y = torch.FloatTensor(2,2)\n",
    "y.requires_grad_(True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    z= (x+y)+torch.FloatTensor(2,2)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3.3 피드포워드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{gathered}\n",
    "y = xW+ b \\\\\n",
    "\\text{where }x\\in\\mathbb{R}^{M\\times N},W\\in\\mathbb{R}^{N\\times P}\\text{ and }b\\in\\mathbb{R}^P. \\\\\n",
    "\\text{Thus, }y\\in\\mathbb{R}^{M\\times P}.\n",
    "\\end{gathered}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T13:46:44.629788Z",
     "start_time": "2020-01-29T13:46:44.622808Z"
    }
   },
   "source": [
    "$$\\begin{aligned}\n",
    "y&=f(x; \\theta)\\text{ where }\\theta=\\{W, b\\}\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T13:12:10.213782Z",
     "start_time": "2020-01-29T13:12:10.193840Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 5])\n",
      "tensor([[1.7131e-05, 2.8064e+00, 7.1395e+00, 9.7797e+00, 5.1319e+02],\n",
      "        [1.6963e-05, 7.3140e+00, 7.5135e+00, 1.9973e+01, 2.6434e+02],\n",
      "        [2.8563e-05, 3.6495e+00, 3.7729e+00, 9.9869e+00, 1.9484e+02],\n",
      "        [2.8075e-05, 3.6501e+00, 3.2566e+00, 9.7785e+00, 3.7730e+02],\n",
      "        [1.6478e-05, 3.1232e+00, 3.8120e+00, 9.7787e+00, 4.6653e+02],\n",
      "        [1.3391e-05, 3.4152e+00, 3.7083e+00, 9.9864e+00, 2.4841e+02],\n",
      "        [2.9243e-05, 3.6498e+00, 3.7795e+00, 9.7802e+00, 2.4937e+02],\n",
      "        [3.3225e-05, 3.6495e+00, 7.3155e+00, 9.7790e+00, 2.4940e+02],\n",
      "        [2.7526e-05, 3.6492e+00, 3.8419e+00, 9.7799e+00, 1.3486e+02],\n",
      "        [1.5825e-05, 7.0624e+00, 3.0358e+00, 9.7792e+00, 2.6332e+02],\n",
      "        [1.6415e-05, 3.6498e+00, 3.7222e+00, 9.9867e+00, 2.4936e+02],\n",
      "        [3.4856e-06, 6.5156e+00, 3.6786e+00, 9.7784e+00, 4.9655e+02],\n",
      "        [2.9263e-05, 6.2719e-03, 3.8512e+00, 1.8926e+01, 1.4218e+02],\n",
      "        [2.8448e-05, 3.6486e+00, 3.6402e+00, 9.7783e+00, 1.7946e+01],\n",
      "        [1.6462e-05, 7.2887e+00, 3.7235e+00, 1.7673e+01, 2.6420e+02],\n",
      "        [1.1134e-06, 3.1188e-01, 2.1022e-02, 6.3150e-03, 2.3573e+02]])\n"
     ]
    }
   ],
   "source": [
    "def linear(x,W,b):\n",
    "    y = torch.mm(x,W)+b #matrix multiplication\n",
    "    \n",
    "    return y\n",
    "\n",
    "x= torch.FloatTensor(16,10)\n",
    "W = torch.FloatTensor(10,5)\n",
    "b = torch.FloatTensor(5)\n",
    "\n",
    "y = linear(x,W,b)\n",
    "print(y.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "선형 계층의 기능을 위와 같이 파이토치로 구현 가능. 다만 이 경우에는 역전파 알고리즘을 통한 학습은 할 수 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3.4 nn.Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn.Module 이라는 클래스를 사용하여 사용자가 그 클래스 위에서 필요한 모델 구조를 구현할 수 있도록 함\n",
    "\n",
    "nn.Module을 상속한 사용자 정의 클래스는 다시 내부에 nn.Module을 상속한 클래스 객체를 선언하여 소유할 수 있음\n",
    "\n",
    "- nn.Module의 forward() 함수를 오버라이드해서 피드포워드 구현 가능\n",
    "- 이외에도 nn.Module 특징을 이용해서 한 번에 신경망 가중치 파라미터들을 저장 및 불러오기를 수행 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T13:24:12.539653Z",
     "start_time": "2020-01-29T13:24:12.532676Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MyLinear(nn.Module):\n",
    "    def __init__(self,input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.W = torch.FloatTensor(input_size, output_size)\n",
    "        self.b = torch.FloatTensor(output_size)\n",
    "\n",
    "    def forward(self,x):\n",
    "        y = torch.mm(x, self.W) + self.b\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn.Module의 forward() 함수를 오버라이드하여 피드포워드를 구현할 수 있음\n",
    "\n",
    "* 오버라이드 (override)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T13:24:12.957531Z",
     "start_time": "2020-01-29T13:24:12.943575Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 5])\n",
      "tensor([[3.5487e-06, 7.2876e+00, 1.9539e-02, 6.3154e-03, 2.9904e+01],\n",
      "        [9.0550e-07, 2.5775e-03, 9.7295e-01, 6.3149e-03, 6.2317e+01],\n",
      "        [9.0546e-07, 4.1129e-03, 9.9674e-01, 2.5981e+00, 4.6839e+02],\n",
      "        [3.4893e-06, 9.7563e-01, 1.8105e-02, 6.3150e-03, 4.1345e+00],\n",
      "        [2.7492e-06, 2.5913e-03, 2.9653e+00, 2.6157e+00, 6.2705e+01],\n",
      "        [3.4883e-06, 9.7598e-01, 1.8101e-02, 6.3150e-03, 4.1360e+00],\n",
      "        [9.1135e-07, 3.8590e-03, 9.9917e-01, 2.6156e+00, 4.0071e+02],\n",
      "        [3.5585e-06, 6.2352e+00, 1.9388e-02, 6.3153e-03, 2.5607e+01],\n",
      "        [9.1138e-07, 2.5913e-03, 9.7956e-01, 2.6158e+00, 6.2707e+01],\n",
      "        [1.0001e-05, 9.7557e-01, 4.7162e-02, 6.3150e-03, 4.1343e+00],\n",
      "        [9.1021e-07, 2.5913e-03, 9.7829e-01, 2.6112e+00, 6.2709e+01],\n",
      "        [3.4846e-06, 9.7455e-01, 1.8084e-02, 6.3150e-03, 4.1301e+00],\n",
      "        [8.9300e-07, 2.5742e-03, 9.5940e-01, 6.3149e-03, 6.1438e+01],\n",
      "        [8.9308e-07, 3.0322e-03, 9.6710e-01, 8.3539e+00, 1.8026e+02],\n",
      "        [3.4176e-06, 9.5589e-01, 1.7782e-02, 6.3150e-03, 4.0539e+00],\n",
      "        [2.8930e-06, 2.5865e-03, 3.1206e+00, 2.5617e+00, 6.1436e+01]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor(16,10)\n",
    "linear = MyLinear(10,5)\n",
    "y = linear(x)\n",
    "print(y.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T13:27:23.855444Z",
     "start_time": "2020-01-29T13:27:23.846465Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "params = [p.size() for p in linear.parameters()]\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고: http://pytorch.org/docs/master/nn.html?highlight=parameter#parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위와 같이 W,b를 선언하면 문제가 있음\n",
    "\n",
    "- linear 모듈 내에서는 학습 가능한 파라미터가 없음\n",
    "- 신경망의 학습 파라미터는 단순한 텐서가 아니기 때문에 파라미터로 등록되어야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T13:29:50.592341Z",
     "start_time": "2020-01-29T13:29:50.583362Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyLinear(nn.Module):\n",
    "    def __init__(self,input_size, output_size):\n",
    "        super(MyLinear,self).__init__()\n",
    "        \n",
    "        self.W = nn.Parameter(torch.FloatTensor(input_size, output_size),requires_grad=True)\n",
    "        self.b = nn.Parameter(torch.FloatTensor(output_size),requires_grad=True)\n",
    "\n",
    "    def forward(self,x):\n",
    "        y = torch.mm(x, self.W) + self.b\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T13:31:03.036603Z",
     "start_time": "2020-01-29T13:31:03.029627Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([10, 5]), torch.Size([5])]\n"
     ]
    }
   ],
   "source": [
    "linear = MyLinear(10,5)\n",
    "params = [p.size() for p in linear.parameters()]\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다시 깔끔하게 만들기!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T13:32:46.256185Z",
     "start_time": "2020-01-29T13:32:46.249186Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyLinear(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_size,output_size):\n",
    "        super(MyLinear,self).__init__()\n",
    "        \n",
    "        self.linear = nn.Linear(input_size,output_size)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        y = self.linear(x)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T13:33:06.964776Z",
     "start_time": "2020-01-29T13:33:06.956830Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyLinear(\n",
      "  (linear): Linear(in_features=10, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "linear = MyLinear(10,5)\n",
    "print(linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3.5 역전파 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T13:40:25.743880Z",
     "start_time": "2020-01-29T13:40:25.731919Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9779.7529, grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "objective= 100\n",
    "\n",
    "x=  torch.FloatTensor(16,10)\n",
    "linear = MyLinear(10,5)\n",
    "y = linear(x)\n",
    "loss = (objective - y.sum())**2\n",
    "loss.backward()\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "에러(손실) 값은 스칼라로 표현되어야 한다. 벡터나 행렬의 형태여서는 안 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3.6 train() 과 eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T13:43:44.563399Z",
     "start_time": "2020-01-29T13:43:44.557400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyLinear(\n",
       "  (linear): Linear(in_features=10, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training...\n",
    "linear.eval()\n",
    "#do some inference process\n",
    "linear.train()\n",
    "#restart training,again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train()과 eval()을 통해서 사용자는 필요에 따라 모델에 대해 훈련 시와 추론 시의 모드를 쉽게 전환할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- nn.Module을 상속받아 구현하고 생성한 객체는 기본적으로 훈련 모드이다.\n",
    "- eval()을 사용하여 추론 모드로 바꿔어주면, 드롭아웃, 배치 정규화와 같은 학습과 추론 시 서로 다른 forward() 동작을 하는 모듈들에 대해서도 각 상황에 따라 올바르게 동작함\n",
    "- 다만 추론이 끝나면 다시 train()을 선언하여 원래의 훈련 모드로 돌아가게 해줘야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3.7 선형회귀분석 예제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\mathcal{L}_{\\text{MSE}}(\\hat{y}, y)=\\frac{1}{N}\\sum^N_{i=1}{(\\hat{y}_i - y_i)^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T13:58:37.954100Z",
     "start_time": "2020-01-29T13:58:37.947150Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_size, output_size):\n",
    "        super(MyModel,self).__init__()\n",
    "        \n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        y = self.linear(x)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{gathered}\n",
    "y=f(x_1, x_2, x_3) = 3x_1 + x_2 - 2x_3 \\\\\n",
    "\\hat{y}=\\tilde{f}(x_1,x_2,x_3;\\theta) \\\\\n",
    "\\hat{\\theta}=\\underset{\\theta\\in\\Theta}{\\text{argmin }}\\mathcal{L}(\\hat{y},y)\n",
    "\\end{gathered}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T13:58:38.640297Z",
     "start_time": "2020-01-29T13:58:38.635280Z"
    }
   },
   "outputs": [],
   "source": [
    "def ground_truth(x):\n",
    "    return 3*x[:,0]+x[:,1]-2*x[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T13:58:39.025263Z",
     "start_time": "2020-01-29T13:58:39.019283Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model,x,y,optim):\n",
    "    #initialize gradients in all parameters in module\n",
    "    optim.zero_grad()\n",
    "    \n",
    "    #feed-forward\n",
    "    y_hat= model(x)\n",
    "    #get error between anser and inferenced.\n",
    "    loss = ((y-y_hat)**2).sum() / x.size(0)\n",
    "    \n",
    "    #back-propagation\n",
    "    loss.backward()\n",
    "    \n",
    "    #one-step of gradient descent\n",
    "    optim.step()\n",
    "    \n",
    "    return loss.data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T13:58:39.511936Z",
     "start_time": "2020-01-29T13:58:39.501963Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel(\n",
      "  (linear): Linear(in_features=3, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "batch_size= 1\n",
    "n_epochs= 1000\n",
    "n_iter =10000\n",
    "\n",
    "model = MyModel(3,1)\n",
    "optim = torch.optim.SGD(model.parameters(),lr= 0.0001, momentum = 0.1)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T14:01:29.709674Z",
     "start_time": "2020-01-29T14:01:12.089805Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0020) tensor(0.9000) tensor(0.9524)\n",
      "tensor(0.0015) tensor(0.9000) tensor(0.9466)\n",
      "tensor(0.0011) tensor(0.9000) tensor(0.9427)\n",
      "tensor(0.0009) tensor(0.9000) tensor(0.9391)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    avg_loss =0\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        x= torch.rand(batch_size,3)\n",
    "        y= ground_truth(x.data)\n",
    "        loss =train(model, x, y, optim)\n",
    "        \n",
    "        avg_loss +=loss\n",
    "    avg_loss = avg_loss /n_iter\n",
    "        \n",
    "    #simple test sample to check the network\n",
    "    x_valid = torch.FloatTensor([[.3,.2,.1]])\n",
    "    y_valid = ground_truth(x_valid.data)\n",
    "    \n",
    "    model.eval()\n",
    "    y_hat = model(x_valid)\n",
    "    model.train()\n",
    "    \n",
    "    print(avg_loss, y_valid.data[0],y_hat.data[0,0])\n",
    "    \n",
    "    if avg_loss <.001: #finish the training if the loss is smaller than .001.\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파이토치에서 딥러닝을 수행하는 과정을 다음과 같이 요약 가능\n",
    "\n",
    "1. nn.Module 클래스를 상속받아 (forward 함수를 통해) 모델 아키텍쳐 클래스 선언\n",
    "2. 해당 클래스 객체 생성\n",
    "3. SGD나 Adam 등의 옵티마이저를 생성하고, 생성한 모델의 파라미터를 최적화 대상으로 등록\n",
    "4. 데이터로 미니배치를 구성하여 피드포워드 연산 그래프 생성\n",
    "5. 손실 함수를 통해 최종 결과값(scalar)과 손실값(loss) 계산\n",
    "6. 손실에 대해서 backward() 호출- > 연산 그래프 상의 텐서들의 기울기가 채워짐\n",
    "7. 3번의 옵티마이저에서 step()을 호출하여 경사하강법 1스탭 수행\n",
    "8. 4번으로 돌아가 수렴 조건이 만족할 때까지 반복 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3.8 GPU 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-29T14:06:51.477283Z",
     "start_time": "2020-01-29T14:06:51.466316Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "type torch.cuda.FloatTensor not available. Torch not compiled with CUDA enabled.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-138-74433b78fb4e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#note that tensor is declared in torch.cuda.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mlinear\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMylinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# .cuda() let module move to GPU memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlinear\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: type torch.cuda.FloatTensor not available. Torch not compiled with CUDA enabled."
     ]
    }
   ],
   "source": [
    "#note that tensor is declared in torch.cuda.\n",
    "x= torch.cuda.FloatTensor(16,10)\n",
    "linear = Mylinear(10,5)\n",
    "# .cuda() let module move to GPU memory\n",
    "linear.cuda()\n",
    "y = linear(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> pytorch 설치 시 cpu only version을 설치했기에 나타난 오류로 보임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cuda() 함수를 통해서 원하는 객체를 (텐서의 경우) GPU 메모리에 복사하거나 (nn.Module의 하위 클래스인 경우)이동시킬 수 있음\n",
    "\n",
    "cpu() 함수를 통해서 다시 pc의 메모리로 복사하거나 이동할 수 있음\n",
    "\n",
    "이 밖에도 to() 함수를 사용해서 텐서 또는 모듈을 원하는 디바이스로 보낼 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
